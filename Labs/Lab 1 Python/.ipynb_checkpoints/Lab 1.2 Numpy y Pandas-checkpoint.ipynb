{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p><img alt=\"DataOwl\" width=150 src=\"http://gwsolutions.cl/Images/dataowl.png\", align=\"left\", hspace=0, vspace=5></p>\n",
    "\n",
    "<h1 align=\"center\">Numpy y Pandas</h1>\n",
    "\n",
    "<h4 align=\"center\">Arreglos y Dataframes</h4>\n",
    "<pre><div align=\"center\"> La idea de este notebook es que sirva para iniciarse en el preprocesamiento de datos.</div>\n",
    "\n",
    "\n",
    "<div align=\"right\"> En términos de código y estructura, este notebook esta basado en el BootCamp \n",
    "<a href=\"https://github.com/Shekhar-rv/Python-for-Data-Science-and-Machine-Learning-Bootcamp\">Python for Data Science and Machine Learning</a>.\n",
    ".</div></pre>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ¿Qué es Numpy?\n",
    "\n",
    "<p><img alt=\"Numpy\" width=70 src=\"https://user-images.githubusercontent.com/50221806/81123350-b7c5bb00-8ee7-11ea-9bfc-88f676c80315.png\", align=\"right\", hspace=0, vspace=5></p>\n",
    "\n",
    "NumPy es una extensión de Python, que le agrega mayor soporte para vectores y matrices, constituyendo una biblioteca de funciones matemáticas de alto nivel para operar con esos vectores o matrices.\n",
    "\n",
    "Para instalar la librería puede hacerse a través del comando **pip** o el comando **conda** en la consola de comandos:\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "```cmd\n",
    "conda install numpy\n",
    "\n",
    "pip install numpy\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# Importando la librería\n",
    "\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Numpy nos permite crear y trabajar con vectores (llamados arreglos) y matrices de forma simple, y se enfoca principalmente en añadir funciones matematicas, a diferencia de las listas que son estructuras de mayor complejidad. Existen varias maneras de construir un arreglo, entre ellas la más sencilla es realizarlo a partir de una lista, no obstante, podemos hacerlo a partir de una matriz o de comandos predefinidos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# Creando arreglo a partir de una lista\n",
    "\n",
    "my_list = [1,2,3,4,5]\n",
    "my_array = np.array(my_list)\n",
    "\n",
    "my_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# Creando arreglo a partir de una lista de listas\n",
    "\n",
    "\n",
    "my_list_of_lists = [ [1,2,3] , [4,5,6] , [7,8,9] ]\n",
    "my_array_2 = np.array(my_list_of_lists)\n",
    "\n",
    "my_array_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# Definiendo un array ordenado (Función arange)\n",
    "\n",
    "arr = np.arange(1,11)\n",
    "\n",
    "arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# Definiendo un array de ceros (Función zeros)\n",
    "\n",
    "arr_0 = np.zeros(10)\n",
    "\n",
    "arr_0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# Definiendo un array de unos (Función ones)\n",
    "\n",
    "arr_1 = np.ones(10)\n",
    "\n",
    "arr_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# Definiendo un arreglo equiespaciado\n",
    "\n",
    "arr = np.linspace(0,1,15)\n",
    "\n",
    "arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# Definiendo la matriz identidad\n",
    "\n",
    "\n",
    "arr = np.eye(4)\n",
    "\n",
    "arr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Además de la creación de arreglos, existen además maneras de indexar y operaciones alrededor de los arreglos, no obstante no porfundizaremos en ellos ya que hoy en día esta librería no se utiliza en demasía, por lo que pasaremos a Pandas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ¿Qué es Pandas?\n",
    "<p><img alt=\"Pandas\" width=150 src=\"https://zhihuicao.files.wordpress.com/2016/05/pandas.png?w=399\", align=\"right\", hspace=0, vspace=5></p>\n",
    "\n",
    "Pandas es una biblioteca de software escrita como extensión de NumPy para manipulación y análisis de datos para el lenguaje de programación Python. En particular, ofrece estructuras de datos y operaciones para manipular tablas numéricas y series temporales. \n",
    "\n",
    "Para instalar la librería puede hacerse a través del comando **pip** o el comando **conda** en la consola de comandos:\n",
    "\n",
    "\n",
    "\n",
    "```cmd\n",
    "conda install pandas\n",
    "\n",
    "pip install pandas\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "#Importando la librería\n",
    "\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Secciones</h3>\n",
    "\n",
    "<div class=\"alert alert-danger\" role=\"alert\">\n",
    "<ol>\n",
    "    <li><a href=\"#section1\"> Series</a></li>\n",
    "    <li><a href=\"#section2\"> DataFrames </a></li>\n",
    "    <li><a href=\"#section3\"> Datos faltantes (Missing Data) </a></li>\n",
    "    <li><a href=\"#section4\"> Agrupaciones (Groupby)</a></li>\n",
    "    <li><a href=\"#section5\"> Fusiones (Merge), Uniones (Join) y Concatenaciones</a></li>\n",
    "</ol>\n",
    "</div>\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"section1\"></a>\n",
    "<h3>1. Series</h3>\n",
    "<hr>\n",
    "\n",
    "El primer tipo de datos principal que aprenderemos para los pandas es el tipo de datos **Serie**. Importemos Pandas y exploremos el objeto Serie.\n",
    "\n",
    "<p><img alt=\"Dataframe\" width=150 src=\"https://miro.medium.com/max/1284/1*iI8ltITQlsrX7Mc6E-OKKg.png\", align=\"center\", hspace=0, vspace=5></p>\n",
    "\n",
    "\n",
    "Una serie es muy similar a un arreglo de NumPy (de hecho, está construida sobre el objeto de arreglo de NumPy). Lo que diferencia el arreglo de una Serie es que una Serie puede tener etiquetas de eje, lo que significa que puede ser indexada por una etiqueta, en lugar de solo una ubicación numérica. Tampoco necesita contener datos numéricos, puede contener cualquier objeto Python arbitrario.\n",
    "\n",
    "Una serie puede ser creada a partir de un arreglo, de una lista o de un diccionario."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# Creando una serie\n",
    "\n",
    "labels = ['a','b','c']\n",
    "my_list = [10,20,30]\n",
    "\n",
    "arr = np.array([10,20,30])\n",
    "\n",
    "d = { 'a' : 10 , 'b' : 20 , 'c' : 30 }\n",
    "\n",
    "\n",
    "Serie = pd.Series( d )\n",
    "Serie"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Los índices se utilizan de la misma manera que en las listas, diccionarios o arreglos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# Llamando un elemento de la serie\n",
    "\n",
    "Serie[ ['b','c'] ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cuando operamos dos series tenemos que tener cuidado, ya que estas se operan a partir de las etiquetas, no de la posición que utilizen en esta:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# Operación simple entre series\n",
    "\n",
    "ser_1 = pd.Series([1,2,3,4],index = ['USA', 'Germany','USSR', 'Japan'])\n",
    "ser_2 = pd.Series([1,2,5,4],index = ['USA', 'Germany','Italy', 'Japan'])\n",
    "\n",
    "ser_1+ser_2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"section2\"></a>\n",
    "<h3>2. Dataframe</h3>\n",
    "<hr>\n",
    "\n",
    "Los DataFrames son el caballo de batalla de los pandas y están directamente inspirados en el lenguaje de programación R. Podemos pensar en un DataFrame como una matriz, donde cada columna es una serie. \n",
    "\n",
    "<p><img alt=\"Dataframe\" width=450 src=\"https://vrzkj25a871bpq7t1ugcgmn9-wpengine.netdna-ssl.com/wp-content/uploads/2022/01/pandas-dataframe-integer-location.png\", align=\"center\", hspace=0, vspace=5></p>\n",
    "\n",
    "Las columnas nos representan variables y las filas los datos, algunas veces indexados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# Creando nuestro primer dataframe\n",
    "\n",
    "arr = np.array([[1,2,3,4],[5,6,7,8],[9,10,11,12]])\n",
    "\n",
    "df_1 = pd.DataFrame( data = arr )\n",
    "df_2 = pd.DataFrame( data = arr , index = [\"d_1\",\"d_2\",\"d_3\"] , columns = [\"V_1\",\"V_2\",\"V_3\",\"V_4\"])\n",
    "df_2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Leyendo y guardando ficheros\n",
    "No solo podemos crear dataframes a partir de objetos creados en Python, además podemos leer datos de nuestra propia base datos o de un directorio externo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# Leyendo un archivo .csv\n",
    "\n",
    "df_covid19 = pd.read_csv(\"cases_country.csv\")\n",
    "df_covid19"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# Leyendo archivo desde url\n",
    "\n",
    "df_covid19_url = pd.read_csv(\"https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/csse_covid_19_data/csse_covid_19_time_series/time_series_covid19_confirmed_global.csv\")\n",
    "df_covid19_url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Guardando un archivo localmente\n",
    "\n",
    "df_covid19_url.to_csv(\"df_covid19.csv\" , index=\"False\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Selección por columnas\n",
    "Como ahora estamos trabajando con matrices, podemos querer seleccionar tanto por variables (Columnas) como por datos (Filas), por lo cual existen distintas formas de indexación, la primera a ver será la indexación por columnas.\n",
    "\n",
    "Si indexamos 1 columna, entonces obtenemos una serie por resultado, pero si indexamos una lista de columnas obtenemos un dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# Seleccionando 1 columna\n",
    "\n",
    "df_covid19[\"Country_Region\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# Seleccionando 4 columnas\n",
    "\n",
    "df = df_covid19[ [\"Country_Region\",\"Confirmed\",\"Deaths\",\"Recovered\"] ]\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Trabajando con variables\n",
    "\n",
    " * Para generar una nueva variable (columna) basta con crearla como si estuvieramos seleccionandola, y asignarle su valor.\n",
    " * Para eliminar una variable se utiliza la función **.drop( )**\n",
    " * Podemos indexar condiciones para establecer condiciones sobre las variables\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# Creando una nueva variable\n",
    "\n",
    "df[\"Active\"] = df[\"Confirmed\"]-df[\"Deaths\"]-df[\"Recovered\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# Eliminando la variable\n",
    "\n",
    "df = df.drop(\"Active\" , axis = 1)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# Condicionando variables\n",
    "\n",
    "df_high_deaths = df[ df[\"Deaths\"]>10000 ]\n",
    "df_high_deaths"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Indexación por filas\n",
    "\n",
    "Para comenzar, podemos establecer que una de nuestras columnas sea el indice para nuestro dataframe, para esto utilizamos la funcion **.set_index( )**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Escogiendo un índice\n",
    "\n",
    "df = df.set_index(\"Country_Region\")\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para escoger 1 o 2 datos, utilizamos la función **.loc[ ]**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# Escogiendo datos particulares\n",
    "\n",
    "df.loc[ [\"Argentina\",\"Chile\"]  ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"section3\"></a>\n",
    "<h3>3. Datos faltantes (Missing Data)</h3>\n",
    "<hr>\n",
    "\n",
    "Generalmente los datos vienen con valores faltantes en algunas de sus columnas, y esto puede traernos problema a la hora de trabajar y establecer criterios de decisión con la información que obtenemos de estos.\n",
    "\n",
    "Debemos saber que hacer con la data que falta y cuándo hacerlo, para así no tener problemas a la hora de establecer un modelo, o obtener insights. \n",
    "\n",
    "Hay 3 formas usuales de trabajar con datos faltantes:\n",
    " \n",
    " 1. La primera es simplemente eliminar las filas con datos faltantes, y evitarse el riesgo de asignar mal un valor. El problema que esto podría traer es que estamos omitiendo información relevante de nuestra muestra.\n",
    " 2. La segunda es rellenar con algun valor determinado, ya sea la media, mediana u otro que nosotros consideremos. Aquí podríamos estar centralizando demasiado nuestros datos, y cuando las desviaciones son altas este método no es muy efectivo.\n",
    " 3. Otro método consiste en utilizar modelos para tratar de predecir o remplanzar los datos faltantes, aunque esto podría tomarnos mucho tiempo y recursos.\n",
    " \n",
    "\n",
    "<p><img alt=\"Multiple_Imputation\" width=450 src=\"https://media.springernature.com/lw785/springer-static/image/chp%3A10.1007%2F978-3-319-43742-2_13/MediaObjects/339333_1_En_13_Fig3_HTML.gif\", align=\"center\", hspace=0, vspace=5></p>\n",
    "\n",
    "En Python las funciones que nos ayudan a esto son **.dropna( )** para eliminar y la función **.fillna( )** para rellenar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Consideramos este dataframe\n",
    "\n",
    "df = pd.DataFrame({'v_1':[1,2,np.nan],\n",
    "                  'v_2':[5,np.nan,np.nan],\n",
    "                  'v_3':[1,2,3]})\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Eliminando filas con NA\n",
    "\n",
    "df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# Eliminando columnas con NA\n",
    "\n",
    "df.dropna(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# Eliminando filas que tengan mas de n datos faltantes\n",
    "\n",
    "n = 2\n",
    "df.dropna( thresh=n , axis = 1)\n",
    "\n",
    "# Esto se puede replicar para columnas con axis=1 en los argumentos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Llenando con el promedio\n",
    "for i in df.columns:\n",
    "    df[i] = df[i].fillna( value = df[i].mean() )\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"section4\"></a>\n",
    "<h3>4. Agrupaciones (Groupby)</h3>\n",
    "<hr>\n",
    "\n",
    "Para agrupar los datos en varios dataframes utilizando valores que se repitan en alguna de sus variables, utilizamos la funcion **.groupby( )**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Agrupamos el conjunto por paises\n",
    "\n",
    "df = df_covid19_url.dropna()\n",
    "countrys = df.groupby(\"Country/Region\")\n",
    "countrys"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cuando ya tenemos agrupados los datos por alguna variable podemos hacer diversas operaciones, entre ellas estan\n",
    " \n",
    " * Suma con la funcion **.sum( )**\n",
    " * Calcular el promedio con **.mean( )**\n",
    " * Calcular mínimo y máximo con **.max( )** y **.min( )** respectivamente.\n",
    " * Contar cuantos datos hay con **.count( )**\n",
    " * Realizar estadística descriptiva con **.describe( )**\n",
    " \n",
    "Ademas con la función **.get_group( )** podemos obtener un dataframe específico."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# Hacemos una suma sobre los grupos\n",
    "\n",
    "countrys.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [],
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Podemos obtener el dataframe de un elemento en particular\n",
    "\n",
    "countrys.get_group(\"Australia\").describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"section5\"></a>\n",
    "<h3>5. Fusiones (Merges), Uniones (Joins) y Concatenaciones</h3>\n",
    "<hr>\n",
    "Las siguientes operaciones que veremos entre dataframes nos permiten realizar uniones de algún tipo con 2 dataframes.\n",
    "\n",
    "#### Join\n",
    "\n",
    "Entre las tres operaciones de DataFrame, **join()** es la más sencilla y la que menos control nos da sobre la unión. Combina todas las columnas existentes en dos tablas, y las columnas en común las renombrara con un *lsuffix* y un *rsuffix* definidos.\n",
    "\n",
    "Existen a su ves varios tipos de join, los cuales se deben definir en los argumentos de la función con un argumento *how*.\n",
    "\n",
    "<p><img alt=\"Join\" width=750 src=\"https://miro.medium.com/max/1400/1*-I_1qa5TIiB5eNYxnodfAA.png\", align=\"center\", hspace=0, vspace=5></p>\n",
    "\n",
    "\n",
    "```Python\n",
    "df.join(self, how='left', lsuffix='', rsuffix='')\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# Definimos los dataframes para el join()\n",
    "\n",
    "df_1 = pd.DataFrame({'A': ['A0', 'A1', 'A2'],\n",
    "                     'B': ['B0', 'B1', 'B2']},\n",
    "                    index=['K0', 'K1', 'K2'])\n",
    "\n",
    "df_2 = pd.DataFrame({'B': ['B0', 'B1', 'B2'],\n",
    "                     'C': ['C0', 'C2', 'C3'],\n",
    "                     'D': ['D0', 'D2', 'D3']},\n",
    "                    index=['K0', 'K2', 'K3'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# Visualizamos el primer Dataframe\n",
    "\n",
    "df_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# Visualizamos el segundo Dataframe\n",
    "\n",
    "df_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# Realizamos el join()\n",
    "\n",
    "df_join = df_1.join(df_2, how='outer', lsuffix='_1', rsuffix='_2')\n",
    "df_join"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Merge\n",
    "\n",
    "Similar al join, el **merge()** también combina todas las columnas de dos tablas, con las columnas comunes renombradas con los sufijos definidos. Sin embargo, el merge proporciona tres formas de control flexible sobre la alineación en filas:\n",
    "\n",
    " 1. La primera forma es usar *on = COLUMN NAME*, aquí la columna dada debe ser la columna común en ambas tablas.\n",
    " \n",
    " 2. La segunda forma es usar *left_on = COLUMN NAME* y *right_on = COLUMN NAME*, y permite alinear las dos tablas usando dos columnas diferentes. \n",
    " \n",
    " 3. La tercera forma es usar *left_index = True* y *right_index = True*, y las dos tablas están alineadas en función de su índice.\n",
    " \n",
    " \n",
    " \n",
    " ```Python\n",
    " pd.merge(left, right, how='inner', on=None, left_on=None, right_on=None,\n",
    "         left_index=False, right_index=False, suffixes=('_x', '_y'))\n",
    "    ```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Concatenation\n",
    "\n",
    "A diferencia del join() y del merge(), que por defecto operan en columnas, **concat()** puede realizar tambien operaciones de union para filas. El argumento en este caso es una lista con dataframes.\n",
    "\n",
    "\n",
    ".\n",
    "\n",
    "\n",
    " * *Axis = 1*\n",
    "<p><img alt=\"Join\" width=450 src=\"https://miro.medium.com/max/1400/1*LoUq8uZrbg_tO3t4tqZfqg.png\", align=\"center\", hspace=0, vspace=5></p>\n",
    "\n",
    "\n",
    " * *Axis = 0*\n",
    "<p><img alt=\"Join\" width=450 src=\"https://miro.medium.com/max/1400/1*bQ3Bl6_N_V4er6XZxVxIZA.png\", align=\"center\", hspace=0, vspace=5></p>\n",
    "\n",
    "\n",
    "```Python\n",
    "pd.concat(objs, axis=0, join='outer', join_axes=None, ignore_index=False, keys=None)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ¡Motivense a seguir probando distintas combinaciones en los argumentos de las funciones!\n",
    "\n",
    "**Guía de Uniones:** <a href=\"https://pandas.pydata.org/pandas-docs/stable/user_guide/merging.html\">Click aquí</a>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
